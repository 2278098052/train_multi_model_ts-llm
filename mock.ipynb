{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mock_prob_distribution(input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "    batch_size = input_tensor.size(0)\n",
    "    prob_dist = torch.rand(batch_size, 151246)  # Random values in [0, 1)\n",
    "    prob_dist = F.softmax(prob_dist, dim=1)    # Normalize to sum to 1 per row\n",
    "    return prob_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([\n",
    "    [1, 2, 151643, 151643, 151643],\n",
    "    [3, 151643, 151643, 151643, 151643],\n",
    "    [5, 6, 7, 8, 9],  # 无151643的行\n",
    "    [151643, 151643, 151643, 151643, 151643]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tensor==151643)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True,  True,  True],\n",
       "        [False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pad_indices = mask.int().argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pad_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_pad_mask = ~mask.any(dim=1)\n",
    "no_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pad_indices[no_pad_mask] = tensor.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 5, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pad_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1,      2, 151643, 151643, 151643],\n",
       "        [     3, 151643, 151643, 151643, 151643],\n",
       "        [     5,      6,      7,      8,      9],\n",
       "        [151643, 151643, 151643, 151643, 151643]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = tensor.size(1)+100\n",
    "bsz = 8\n",
    "mask = (tensor == 151643)\n",
    "first_pad_indices = mask.int().argmax(dim=1)\n",
    "no_mask = ~mask.any(dim=1)\n",
    "first_pad_indices[no_mask] = tensor.size(1)\n",
    "min_prompt_len = first_pad_indices.min()\n",
    "max_prompt_len = first_pad_indices.max()\n",
    "\n",
    "total_len = max_seq_len\n",
    "pad_id = 151643\n",
    "tokens = tensor\n",
    "\n",
    "token_logprobs = torch.zeros_like(tokens, dtype=torch.float)\n",
    "\n",
    "prev_pos = 0\n",
    "eos_reached = torch.tensor([False] * bsz, device=\"cuda\")\n",
    "input_text_mask = tokens != pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1,      2, 151643, 151643, 151643],\n",
       "        [     3, 151643, 151643, 151643, 151643],\n",
       "        [     5,      6,      7,      8,      9],\n",
       "        [151643, 151643, 151643, 151643, 151643]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 9, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token = torch.tensor([0]*4)\n",
    "next_token = torch.where(input_text_mask[:,4],tensor[:,4],next_token)\n",
    "next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
